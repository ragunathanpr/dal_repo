{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference : https://towardsdatascience.com/custom-dataset-in-pytorch-part-1-images-2df3152895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from pandas.core.common import flatten\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_path example:  /home/jupyter/dal/deep-active-learning-pytorch/data/deepactlearn/casting_data/casting_data/train/def_front/cast_def_0_5711.jpeg\n",
      "class example:  ok_front\n",
      "Train size: 5306\n",
      "Valid size: 1327\n",
      "Test size: 716\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "#       Create Train, Valid and Test sets\n",
    "####################################################\n",
    "train_data_path = '/home/jupyter/dal/deep-active-learning-pytorch/data/deepactlearn/casting_data/casting_data/train' \n",
    "test_data_path = '/home/jupyter/dal/deep-active-learning-pytorch/data/deepactlearn/casting_data/casting_data/test'\n",
    "\n",
    "train_image_paths = [] #to store image paths in list\n",
    "classes = [] #to store class values\n",
    "\n",
    "#1.\n",
    "# get all the paths from train_data_path and append image paths and class to to respective lists\n",
    "# eg. train path-> 'images/train/26.Pont_du_Gard/4321ee6695c23c7b.jpg'\n",
    "# eg. class -> 26.Pont_du_Gard\n",
    "for data_path in glob.glob(train_data_path + '/*'):\n",
    "    classes.append(data_path.split('/')[-1]) \n",
    "    train_image_paths.append(glob.glob(data_path + '/*'))\n",
    "    \n",
    "train_image_paths = list(flatten(train_image_paths))\n",
    "random.shuffle(train_image_paths)\n",
    "\n",
    "print('train_image_path example: ', train_image_paths[0])\n",
    "print('class example: ', classes[0])\n",
    "\n",
    "#2.\n",
    "# split train valid from train paths (80,20)\n",
    "train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):] \n",
    "\n",
    "#3.\n",
    "# create the test_image_paths\n",
    "test_image_paths = []\n",
    "for data_path in glob.glob(test_data_path + '/*'):\n",
    "    test_image_paths.append(glob.glob(data_path + '/*'))\n",
    "\n",
    "test_image_paths = list(flatten(test_image_paths))\n",
    "\n",
    "print(\"Train size: {}\\nValid size: {}\\nTest size: {}\".format(len(train_image_paths), len(valid_image_paths), len(test_image_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################\n",
    "#      Create dictionary for class indexes\n",
    "#######################################################\n",
    "\n",
    "idx_to_class = {i:j for i, j in enumerate(classes)}\n",
    "class_to_idx = {value:key for key,value in idx_to_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#               Define Dataset Class\n",
    "#######################################################\n",
    "\n",
    "class PreneshData(Dataset):\n",
    "    def __init__(self, image_paths, transform=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        label = image_filepath.split('/')[-2]\n",
    "        label = class_to_idx[label]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PreneshData(train_image_paths, train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of tensor for 50th image in train dataset:  torch.Size([3, 300, 300])\n",
      "The label for 50th image in train dataset:  0\n"
     ]
    }
   ],
   "source": [
    "print('The shape of tensor for 50th image in train dataset: ',train_dataset[49][0].shape)\n",
    "print('The label for 50th image in train dataset: ',train_dataset[49][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('dal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e45675ccc9d451fc74d24683826f6efa17114ef91acab0ac59d0540a7bed7dea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
